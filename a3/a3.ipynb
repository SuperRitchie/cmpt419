{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\ritchie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\ritchie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ritchie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ritchie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\ritchie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.13.2)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.16.1-cp312-cp312-win_amd64.whl.metadata (3.5 kB)\n",
      "Collecting keras\n",
      "  Downloading keras-3.1.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ritchie\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ritchie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ritchie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\ritchie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ritchie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ritchie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ritchie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ritchie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ritchie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.45.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ritchie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ritchie\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\ritchie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ritchie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Collecting tensorflow-intel==2.16.1 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.16.1-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading flatbuffers-24.3.7-py2.py3-none-any.whl.metadata (849 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading h5py-3.10.0-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading ml_dtypes-0.3.2-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\ritchie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ritchie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ritchie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (69.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ritchie\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ritchie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.10.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading wrapt-1.16.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading grpcio-1.62.1-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting rich (from keras)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras)\n",
      "  Downloading namex-0.0.7-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras)\n",
      "  Downloading optree-0.10.0-cp312-cp312-win_amd64.whl.metadata (46 kB)\n",
      "     ---------------------------------------- 0.0/46.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 46.1/46.1 kB ? eta 0:00:00\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ritchie\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras) (2.17.2)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ritchie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ritchie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ritchie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ritchie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2023.11.17)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Downloading tensorflow-2.16.1-cp312-cp312-win_amd64.whl (2.1 kB)\n",
      "Downloading tensorflow_intel-2.16.1-cp312-cp312-win_amd64.whl (377.1 MB)\n",
      "   ---------------------------------------- 0.0/377.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/377.1 MB 20.9 MB/s eta 0:00:18\n",
      "   ---------------------------------------- 3.3/377.1 MB 35.8 MB/s eta 0:00:11\n",
      "    --------------------------------------- 4.8/377.1 MB 34.5 MB/s eta 0:00:11\n",
      "    --------------------------------------- 7.5/377.1 MB 39.8 MB/s eta 0:00:10\n",
      "    --------------------------------------- 9.4/377.1 MB 40.2 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 11.4/377.1 MB 43.5 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 13.3/377.1 MB 43.5 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 15.3/377.1 MB 46.7 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 17.4/377.1 MB 40.9 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 19.3/377.1 MB 40.9 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 21.3/377.1 MB 40.9 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 23.2/377.1 MB 40.9 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 25.2/377.1 MB 40.9 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 27.1/377.1 MB 40.9 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 27.6/377.1 MB 36.3 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 28.3/377.1 MB 38.6 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 29.0/377.1 MB 29.8 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 31.2/377.1 MB 29.8 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 33.3/377.1 MB 31.2 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 35.3/377.1 MB 31.2 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 37.3/377.1 MB 31.2 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 39.2/377.1 MB 43.5 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 41.2/377.1 MB 40.9 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 43.2/377.1 MB 40.9 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 45.1/377.1 MB 40.9 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 47.2/377.1 MB 40.9 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 48.3/377.1 MB 38.6 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 50.6/377.1 MB 40.9 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 53.0/377.1 MB 40.9 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 55.0/377.1 MB 40.9 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 56.9/377.1 MB 40.9 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 58.9/377.1 MB 43.5 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 60.8/377.1 MB 43.7 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 62.8/377.1 MB 40.9 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 64.7/377.1 MB 40.9 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 66.1/377.1 MB 40.9 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 66.1/377.1 MB 40.9 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 66.1/377.1 MB 40.9 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 66.1/377.1 MB 40.9 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 66.1/377.1 MB 40.9 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 66.5/377.1 MB 21.1 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 68.9/377.1 MB 21.1 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 69.2/377.1 MB 21.9 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 70.9/377.1 MB 19.8 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 73.3/377.1 MB 19.8 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 75.3/377.1 MB 19.8 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 77.3/377.1 MB 36.3 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 79.2/377.1 MB 36.3 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 81.1/377.1 MB 43.7 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 83.1/377.1 MB 40.9 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 85.1/377.1 MB 40.9 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 87.0/377.1 MB 43.7 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 89.0/377.1 MB 40.9 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 91.0/377.1 MB 40.9 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 93.0/377.1 MB 40.9 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 94.9/377.1 MB 40.9 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 96.9/377.1 MB 43.5 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 98.9/377.1 MB 43.5 MB/s eta 0:00:07\n",
      "   ---------- ---------------------------- 100.8/377.1 MB 43.5 MB/s eta 0:00:07\n",
      "   ---------- ---------------------------- 102.8/377.1 MB 43.7 MB/s eta 0:00:07\n",
      "   ---------- ---------------------------- 104.7/377.1 MB 43.7 MB/s eta 0:00:07\n",
      "   ----------- --------------------------- 106.6/377.1 MB 43.7 MB/s eta 0:00:07\n",
      "   ----------- --------------------------- 108.6/377.1 MB 43.7 MB/s eta 0:00:07\n",
      "   ----------- --------------------------- 110.5/377.1 MB 43.7 MB/s eta 0:00:07\n",
      "   ----------- --------------------------- 112.5/377.1 MB 43.5 MB/s eta 0:00:07\n",
      "   ----------- --------------------------- 114.4/377.1 MB 43.5 MB/s eta 0:00:07\n",
      "   ------------ -------------------------- 116.4/377.1 MB 43.5 MB/s eta 0:00:06\n",
      "   ------------ -------------------------- 118.3/377.1 MB 43.7 MB/s eta 0:00:06\n",
      "   ------------ -------------------------- 120.3/377.1 MB 43.7 MB/s eta 0:00:06\n",
      "   ------------ -------------------------- 122.3/377.1 MB 43.7 MB/s eta 0:00:06\n",
      "   ------------ -------------------------- 124.2/377.1 MB 43.7 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 126.2/377.1 MB 43.7 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 128.2/377.1 MB 43.5 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 130.0/377.1 MB 40.9 MB/s eta 0:00:07\n",
      "   ------------- ------------------------- 132.0/377.1 MB 40.9 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 133.9/377.1 MB 40.9 MB/s eta 0:00:06\n",
      "   -------------- ------------------------ 135.9/377.1 MB 40.9 MB/s eta 0:00:06\n",
      "   -------------- ------------------------ 137.9/377.1 MB 40.9 MB/s eta 0:00:06\n",
      "   -------------- ------------------------ 139.8/377.1 MB 40.9 MB/s eta 0:00:06\n",
      "   -------------- ------------------------ 141.7/377.1 MB 40.9 MB/s eta 0:00:06\n",
      "   -------------- ------------------------ 143.6/377.1 MB 40.9 MB/s eta 0:00:06\n",
      "   --------------- ----------------------- 145.5/377.1 MB 40.9 MB/s eta 0:00:06\n",
      "   --------------- ----------------------- 147.6/377.1 MB 40.9 MB/s eta 0:00:06\n",
      "   --------------- ----------------------- 149.6/377.1 MB 40.9 MB/s eta 0:00:06\n",
      "   --------------- ----------------------- 151.5/377.1 MB 43.7 MB/s eta 0:00:06\n",
      "   --------------- ----------------------- 153.5/377.1 MB 43.7 MB/s eta 0:00:06\n",
      "   ---------------- ---------------------- 155.5/377.1 MB 43.7 MB/s eta 0:00:06\n",
      "   ---------------- ---------------------- 157.5/377.1 MB 43.7 MB/s eta 0:00:06\n",
      "   ---------------- ---------------------- 159.5/377.1 MB 43.5 MB/s eta 0:00:05\n",
      "   ---------------- ---------------------- 161.4/377.1 MB 43.5 MB/s eta 0:00:05\n",
      "   ---------------- ---------------------- 162.5/377.1 MB 40.9 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 164.9/377.1 MB 40.9 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 167.1/377.1 MB 40.9 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 169.1/377.1 MB 40.9 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 171.0/377.1 MB 40.9 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 173.0/377.1 MB 46.7 MB/s eta 0:00:05\n",
      "   ------------------ -------------------- 175.0/377.1 MB 43.5 MB/s eta 0:00:05\n",
      "   ------------------ -------------------- 176.9/377.1 MB 43.5 MB/s eta 0:00:05\n",
      "   ------------------ -------------------- 178.9/377.1 MB 43.5 MB/s eta 0:00:05\n",
      "   ------------------ -------------------- 180.9/377.1 MB 43.7 MB/s eta 0:00:05\n",
      "   ------------------ -------------------- 182.8/377.1 MB 40.9 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 184.7/377.1 MB 40.9 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 186.7/377.1 MB 40.9 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 188.6/377.1 MB 40.9 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 190.5/377.1 MB 40.9 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 192.5/377.1 MB 40.9 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 194.5/377.1 MB 40.9 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 196.4/377.1 MB 40.9 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 198.4/377.1 MB 40.9 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 200.4/377.1 MB 40.9 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 202.4/377.1 MB 40.9 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 204.4/377.1 MB 40.9 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 206.3/377.1 MB 40.9 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 208.3/377.1 MB 40.9 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 210.2/377.1 MB 40.9 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 210.8/377.1 MB 40.9 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 212.5/377.1 MB 36.4 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 214.9/377.1 MB 36.4 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 216.9/377.1 MB 36.4 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 218.8/377.1 MB 36.4 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 220.8/377.1 MB 36.4 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 222.7/377.1 MB 43.5 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 224.7/377.1 MB 40.9 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 226.6/377.1 MB 40.9 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 228.4/377.1 MB 40.9 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 230.3/377.1 MB 40.9 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 232.3/377.1 MB 40.9 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 234.3/377.1 MB 40.9 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 236.2/377.1 MB 40.9 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 238.2/377.1 MB 40.9 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 240.2/377.1 MB 40.9 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 242.2/377.1 MB 40.9 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 244.1/377.1 MB 40.9 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 246.1/377.1 MB 40.9 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 248.1/377.1 MB 40.9 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 250.0/377.1 MB 40.9 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 252.0/377.1 MB 40.9 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 254.0/377.1 MB 40.9 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 256.0/377.1 MB 40.9 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 257.9/377.1 MB 40.9 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 259.9/377.1 MB 40.9 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 261.9/377.1 MB 40.9 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 263.8/377.1 MB 40.9 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 265.8/377.1 MB 40.9 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 267.8/377.1 MB 40.9 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 269.7/377.1 MB 40.9 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 271.8/377.1 MB 40.9 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 272.6/377.1 MB 43.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 272.6/377.1 MB 43.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 272.6/377.1 MB 43.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 272.6/377.1 MB 43.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 272.6/377.1 MB 43.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 273.4/377.1 MB 21.1 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 276.0/377.1 MB 21.8 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 277.9/377.1 MB 22.6 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 279.9/377.1 MB 21.9 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 281.9/377.1 MB 21.9 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 283.8/377.1 MB 46.7 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 285.8/377.1 MB 43.7 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 287.7/377.1 MB 40.9 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 289.7/377.1 MB 43.7 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 291.5/377.1 MB 43.7 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 293.6/377.1 MB 43.7 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 293.6/377.1 MB 40.9 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 295.5/377.1 MB 36.3 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 295.7/377.1 MB 34.4 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 297.6/377.1 MB 31.2 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 299.9/377.1 MB 32.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 301.8/377.1 MB 32.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 303.8/377.1 MB 32.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 305.8/377.1 MB 38.5 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 306.8/377.1 MB 40.9 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 309.1/377.1 MB 40.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 311.4/377.1 MB 40.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 313.5/377.1 MB 43.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 314.6/377.1 MB 40.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 316.9/377.1 MB 43.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 319.2/377.1 MB 43.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 321.3/377.1 MB 43.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 323.3/377.1 MB 40.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 325.3/377.1 MB 43.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 327.3/377.1 MB 43.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 329.3/377.1 MB 40.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 331.2/377.1 MB 40.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 333.0/377.1 MB 40.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 334.9/377.1 MB 40.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 336.9/377.1 MB 40.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 338.9/377.1 MB 40.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 340.9/377.1 MB 40.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 342.9/377.1 MB 40.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 344.9/377.1 MB 40.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 346.3/377.1 MB 38.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 348.8/377.1 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 350.8/377.1 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 352.8/377.1 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 354.8/377.1 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 356.7/377.1 MB 43.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 358.8/377.1 MB 43.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 360.8/377.1 MB 43.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 362.5/377.1 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 364.6/377.1 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 365.5/377.1 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  368.0/377.1 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  370.1/377.1 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  372.0/377.1 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  374.0/377.1 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  376.0/377.1 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.1/377.1 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.1/377.1 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.1/377.1 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.1/377.1 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.1/377.1 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.1/377.1 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.1/377.1 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.1/377.1 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.1/377.1 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.1/377.1 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.1/377.1 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.1/377.1 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------- 377.1/377.1 MB 13.3 MB/s eta 0:00:00\n",
      "Downloading keras-3.1.0-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/1.1 MB 33.8 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.7/133.7 kB 7.7 MB/s eta 0:00:00\n",
      "Downloading h5py-3.10.0-cp312-cp312-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 2.3/2.7 MB 49.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 42.0 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.3.2-cp312-cp312-win_amd64.whl (128 kB)\n",
      "   ---------------------------------------- 0.0/128.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 128.6/128.6 kB ? eta 0:00:00\n",
      "Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.10.0-cp312-cp312-win_amd64.whl (220 kB)\n",
      "   ---------------------------------------- 0.0/220.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 220.8/220.8 kB ? eta 0:00:00\n",
      "Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "   ---------------------------------------- 0.0/240.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 240.7/240.7 kB ? eta 0:00:00\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.7-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 0.0/57.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 57.5/57.5 kB ? eta 0:00:00\n",
      "Downloading grpcio-1.62.1-cp312-cp312-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 2.1/3.8 MB 43.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 48.3 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 2.8/26.4 MB 59.0 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 5.0/26.4 MB 52.6 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 6.9/26.4 MB 49.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 8.9/26.4 MB 47.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 10.8/26.4 MB 43.7 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 12.8/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 14.8/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 16.7/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 18.7/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 20.6/26.4 MB 43.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.6/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.6/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 43.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 43.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 34.4 MB/s eta 0:00:00\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "   ---------------------------------------- 0.0/87.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 87.5/87.5 kB ? eta 0:00:00\n",
      "Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "   ---------------------------------------- 0.0/65.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 65.5/65.5 kB ? eta 0:00:00\n",
      "Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 2.1/5.5 MB 44.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 4.4/5.5 MB 46.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 43.8 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-1.16.0-cp312-cp312-win_amd64.whl (37 kB)\n",
      "Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "   ---------------------------------------- 0.0/105.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 105.4/105.4 kB ? eta 0:00:00\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "   ---------------------------------------- 0.0/226.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 226.7/226.7 kB 14.4 MB/s eta 0:00:00\n",
      "Downloading wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "   ---------------------------------------- 0.0/65.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 65.8/65.8 kB ? eta 0:00:00\n",
      "Downloading MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl (17 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, mdurl, MarkupSafe, markdown, h5py, grpcio, google-pasta, gast, absl-py, werkzeug, markdown-it-py, astunparse, tensorboard, rich, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed MarkupSafe-2.1.5 absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.7 gast-0.5.4 google-pasta-0.2.0 grpcio-1.62.1 h5py-3.10.0 keras-3.1.0 libclang-18.1.1 markdown-3.6 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.0.7 opt-einsum-3.3.0 optree-0.10.0 rich-13.7.1 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-intel-2.16.1 termcolor-2.4.0 werkzeug-3.0.1 wheel-0.43.0 wrapt-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas scikit-learn matplotlib seaborn tensorflow keras Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code heavily referenced from ChatGPT, GitHub, GeekforGeeks, and StackOverflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part A - Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a support vector machine using the images from fer2013.csv. Use the Training set for training, and the PrivateTest test set for testing. Report precision, recall, accuracy, F1 score, and create a confusion matrix on the test set, showing the confusions between emotion labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data sample:    emotion                                             pixels     Usage\n",
      "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
      "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
      "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
      "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
      "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n",
      "Public test data sample:        emotion                                             pixels       Usage\n",
      "28709        0  254 254 254 254 254 249 255 160 2 58 53 70 77 ...  PublicTest\n",
      "28710        1  156 184 198 202 204 207 210 212 213 214 215 21...  PublicTest\n",
      "28711        4  69 118 61 60 96 121 103 87 103 88 70 90 115 12...  PublicTest\n",
      "28712        6  205 203 236 157 83 158 120 116 94 86 155 180 2...  PublicTest\n",
      "28713        3  87 79 74 66 74 96 77 80 80 84 83 89 102 91 84 ...  PublicTest\n",
      "Private test data sample:        emotion                                             pixels        Usage\n",
      "32298        0  170 118 101 88 88 75 78 82 66 74 68 59 63 64 6...  PrivateTest\n",
      "32299        5  7 5 8 6 7 3 2 6 5 4 4 5 7 5 5 5 6 7 7 7 10 10 ...  PrivateTest\n",
      "32300        6  232 240 241 239 237 235 246 117 24 24 22 13 12...  PrivateTest\n",
      "32301        4  200 197 149 139 156 89 111 58 62 95 113 117 11...  PrivateTest\n",
      "32302        2  40 28 33 56 45 33 31 78 152 194 200 186 196 20...  PrivateTest\n",
      "Unique values in 'Usage' column: ['Training' 'PublicTest' 'PrivateTest']\n",
      "Accuracy: 0.4471997770966843\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.23      0.30       491\n",
      "           1       1.00      0.07      0.14        55\n",
      "           2       0.38      0.23      0.29       528\n",
      "           3       0.49      0.71      0.58       879\n",
      "           4       0.34      0.40      0.37       594\n",
      "           5       0.66      0.54      0.59       416\n",
      "           6       0.41      0.44      0.42       626\n",
      "\n",
      "    accuracy                           0.45      3589\n",
      "   macro avg       0.53      0.38      0.38      3589\n",
      "weighted avg       0.45      0.45      0.43      3589\n",
      "\n",
      "Confusion Matrix:\n",
      "[[114   0  48 135  97  18  79]\n",
      " [  8   4   5  21   6   2   9]\n",
      " [ 40   0 122 124 112  52  78]\n",
      " [ 28   0  29 628 107  18  69]\n",
      " [ 37   0  50 134 240  10 123]\n",
      " [ 15   0  36  70  31 223  41]\n",
      " [ 28   0  27 177 104  16 274]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# https://pandas.pydata.org/\n",
    "# https://numpy.org/\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "# https://matplotlib.org/\n",
    "# statistical data visualization; https://seaborn.pydata.org/\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'fer2013.csv'  # relative or absolute path to the dataset\n",
    "data = pd.read_csv(file_path, on_bad_lines='skip') # skip bad lines if any\n",
    "\n",
    "data['Usage'] = data['Usage'].astype(str).str.strip() # remove the leading/trailing spaces from the 'Usage' column\n",
    "\n",
    "# \n",
    "train_data = data[data['Usage'] == 'Training'] # backup the original data\n",
    "public_test_data = data[data['Usage'] == 'PublicTest']  # had problems with the 'PublicTest' data\n",
    "test_data = data[data['Usage'] == 'PrivateTest'] # had problems with the 'PrivateTest' data\n",
    "\n",
    "print(\"Training data sample:\", train_data.head()) # make sure the data is loaded correctly\n",
    "print(\"Public test data sample:\", public_test_data.head()) # ...\n",
    "print(\"Private test data sample:\", test_data.head()) # ...\n",
    "\n",
    "def prepare_data(df, expected_pixels=2304):  # 48x48 images have 2304 pixels\n",
    "    pixel_arrays = [] # store the pixel arrays\n",
    "    emotions = [] # store the emotions\n",
    "    for _, row in df.iterrows(): # iterate over the rows of the dataframe\n",
    "        pixel_list = np.fromstring(row['pixels'], dtype=int, sep=' ')\n",
    "        if len(pixel_list) == expected_pixels:\n",
    "            pixel_arrays.append(pixel_list)\n",
    "            emotions.append(row['emotion'])\n",
    "    X = np.array(pixel_arrays)\n",
    "    y = np.array(emotions)\n",
    "    return X, y\n",
    "\n",
    "print(\"Unique values in 'Usage' column:\", data['Usage'].unique()) # check the unique values in the 'Usage' column\n",
    "\n",
    "train_data = data[data['Usage'].str.strip().eq('Training')]\n",
    "test_data = data[data['Usage'].str.strip().eq('PrivateTest')]\n",
    "\n",
    "X_train, y_train = prepare_data(train_data)\n",
    "X_test, y_test = prepare_data(test_data)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "svm_model = SVC(kernel='rbf')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", svm_model.score(X_test, y_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Train a support vector machine using the Action Units of labeled samples from phoebe_AU.csv. Use 5-fold cross-validation on this training set to report the performance. Report your perceived qualitative performance on the unknown labels (e.g. How many appear correct? Provide your own labels as unknown groundtruth to help quantify your results.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 5-Fold CV Score: 0.3968421052631579\n",
      "Actual: unknown, Predicted: surprise\n",
      "Actual: angry, Predicted: sad\n",
      "Actual: surprise, Predicted: surprise\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: unknown, Predicted: unknown\n",
      "Actual: unknown, Predicted: unknown\n",
      "Actual: angry, Predicted: surprise\n",
      "Actual: surprise, Predicted: surprise\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: unknown, Predicted: happy\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: unknown, Predicted: unknown\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: sad, Predicted: sad\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: sad, Predicted: sad\n",
      "Actual: sad, Predicted: sad\n",
      "Actual: sad, Predicted: sad\n",
      "Actual: sad, Predicted: sad\n",
      "Actual: angry, Predicted: angry\n",
      "Actual: angry, Predicted: angry\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: surprise, Predicted: surprise\n",
      "Actual: angry, Predicted: angry\n",
      "Actual: disgust, Predicted: disgust\n",
      "Actual: surprise, Predicted: surprise\n",
      "Actual: happy, Predicted: surprise\n",
      "Actual: sad, Predicted: sad\n",
      "Actual: sad, Predicted: sad\n",
      "Actual: surprise, Predicted: surprise\n",
      "Actual: surprise, Predicted: surprise\n",
      "Actual: surprise, Predicted: surprise\n",
      "Actual: disgust, Predicted: disgust\n",
      "Actual: disgust, Predicted: disgust\n",
      "Actual: angry, Predicted: angry\n",
      "Actual: surprise, Predicted: surprise\n",
      "Actual: surprise, Predicted: surprise\n",
      "Actual: sad, Predicted: sad\n",
      "Actual: angry, Predicted: sad\n",
      "Actual: unknown, Predicted: unknown\n",
      "Actual: disgust, Predicted: happy\n",
      "Actual: disgust, Predicted: disgust\n",
      "Actual: disgust, Predicted: angry\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: sad, Predicted: sad\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: surprise, Predicted: sad\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: disgust, Predicted: happy\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: surprise, Predicted: sad\n",
      "Actual: unknown, Predicted: unknown\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: sad, Predicted: sad\n",
      "Actual: sad, Predicted: sad\n",
      "Actual: angry, Predicted: angry\n",
      "Actual: disgust, Predicted: disgust\n",
      "Actual: surprise, Predicted: surprise\n",
      "Actual: surprise, Predicted: surprise\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: unknown, Predicted: unknown\n",
      "Actual: sad, Predicted: sad\n",
      "Actual: angry, Predicted: happy\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: unknown, Predicted: sad\n",
      "Actual: surprise, Predicted: surprise\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: unknown, Predicted: happy\n",
      "Actual: angry, Predicted: angry\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: unknown, Predicted: unknown\n",
      "Actual: disgust, Predicted: disgust\n",
      "Actual: sad, Predicted: sad\n",
      "Actual: angry, Predicted: sad\n",
      "Actual: sad, Predicted: sad\n",
      "Actual: sad, Predicted: sad\n",
      "Actual: sad, Predicted: sad\n",
      "Actual: surprise, Predicted: sad\n",
      "Actual: sad, Predicted: surprise\n",
      "Actual: unknown, Predicted: surprise\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: happy, Predicted: happy\n",
      "Actual: surprise, Predicted: surprise\n",
      "Actual: happy, Predicted: happy\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.86      0.55      0.67        11\n",
      "     disgust       1.00      0.67      0.80         9\n",
      "       happy       0.86      0.97      0.91        33\n",
      "         sad       0.70      0.94      0.80        17\n",
      "    surprise       0.72      0.81      0.76        16\n",
      "     unknown       1.00      0.58      0.74        12\n",
      "\n",
      "    accuracy                           0.82        98\n",
      "   macro avg       0.86      0.75      0.78        98\n",
      "weighted avg       0.84      0.82      0.81        98\n",
      "\n",
      "[[ 6  0  1  3  1  0]\n",
      " [ 1  6  2  0  0  0]\n",
      " [ 0  0 32  0  1  0]\n",
      " [ 0  0  0 16  1  0]\n",
      " [ 0  0  0  3 13  0]\n",
      " [ 0  0  2  1  2  7]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "data = pd.read_csv('phoebe_AU.csv')\n",
    "\n",
    "X = data.iloc[:, 1:-1]  # exclude the first and last columns\n",
    "y = data.iloc[:, -1]   # we expect the last column to be the target\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "svm_model = SVC(kernel='rbf') # default kernel is 'rbf' and is faster than 'linear' kernel\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "cv_scores = cross_val_score(svm_model, X_scaled, y, cv=kf, scoring='accuracy')\n",
    "print(f\"Average 5-Fold CV Score: {cv_scores.mean()}\")\n",
    "\n",
    "svm_model.fit(X_scaled, y)\n",
    "predicted_labels = svm_model.predict(X_scaled) # compare the predicted labels to the actual labels\n",
    "\n",
    "for actual, predicted in zip(y, predicted_labels):\n",
    "    print(f\"Actual: {actual}, Predicted: {predicted}\")\n",
    "\n",
    "print(classification_report(y, predicted_labels))\n",
    "print(confusion_matrix(y, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After analyzing the model, it seems that it was quite accurate in determining the emotion conveyed for clearly labeled images, while it was still quite uncertain for images labeled as 'unknown'. Based on my own labels as unknown groundtruths, most of the expressions are mixes of angry or sad facial features, but this is not matched with the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part B - Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Neural Network. Train a neural network using the images from fer2013.csv using Keras. Your first layer should be a Conv2D layer, and the last layers should be a Dense layer followed by a Softmax. Use the Training set for training, PublicTest validation set to avoid overfitting, and the PrivateTest test set for testing. Aim for a minimum validation accuracy of 40% on the Fer2013 validation set. To enhance your model's performance, experiment with various batch sizes and epochs. Incorporate dropout and normalization techniques to further mitigate overfitting and improve generalization. Report precision, recall, accuracy, F1 score, and create a confusion matrix on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ritchie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ritchie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m449/449\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 310ms/step - accuracy: 0.2351 - loss: 2.5274 - val_accuracy: 0.2839 - val_loss: 1.8768\n",
      "Epoch 2/5\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 290ms/step - accuracy: 0.3512 - loss: 1.7546 - val_accuracy: 0.2973 - val_loss: 1.9670\n",
      "Epoch 3/5\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 291ms/step - accuracy: 0.3816 - loss: 1.6064 - val_accuracy: 0.3335 - val_loss: 1.9096\n",
      "Epoch 4/5\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 286ms/step - accuracy: 0.4063 - loss: 1.5435 - val_accuracy: 0.4202 - val_loss: 1.6558\n",
      "Epoch 5/5\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 282ms/step - accuracy: 0.4384 - loss: 1.4820 - val_accuracy: 0.4386 - val_loss: 1.5215\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.4213 - loss: 1.5542\n",
      "Test accuracy: 41.99%\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.25      0.30       491\n",
      "           1       0.00      0.00      0.00        55\n",
      "           2       0.31      0.17      0.22       528\n",
      "           3       0.44      0.91      0.60       879\n",
      "           4       0.30      0.37      0.33       594\n",
      "           5       0.75      0.43      0.55       416\n",
      "           6       0.57      0.14      0.23       626\n",
      "\n",
      "    accuracy                           0.42      3589\n",
      "   macro avg       0.39      0.33      0.32      3589\n",
      "weighted avg       0.44      0.42      0.38      3589\n",
      "\n",
      "[[124   0  37 177 121  11  21]\n",
      " [ 17   0   5  18  13   2   0]\n",
      " [ 55   0  91 198 136  32  16]\n",
      " [ 19   0  18 802  33   2   5]\n",
      " [ 55   0  42 255 222   5  15]\n",
      " [ 28   0  67 108  25 178  10]\n",
      " [ 50   0  29 252 198   7  90]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ritchie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Ritchie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Ritchie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "file_path = 'fer2013.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "def prepare_data(df):\n",
    "    X = np.array([np.fromstring(pixels, dtype=float, sep=' ').reshape(48, 48, 1) for pixels in df['pixels']]) # 48x48 images with 1 channel (required by the Conv2D layer)\n",
    "    X = X / 255.0  # normalize the pixel values\n",
    "    y = to_categorical(df['emotion'].values)\n",
    "    return X, y\n",
    "\n",
    "train_data = data[data['Usage'] == 'Training']\n",
    "val_data = data[data['Usage'] == 'PublicTest']\n",
    "test_data = data[data['Usage'] == 'PrivateTest']\n",
    "X_train, y_train = prepare_data(train_data)\n",
    "X_val, y_val = prepare_data(val_data)\n",
    "X_test, y_test = prepare_data(test_data)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(1024, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(7, activation='softmax')  # 7 is the number of emotion labels\n",
    "])\n",
    "\n",
    "# boilerplate model code\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=64),\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, to_categorical(test_data['emotion'].values))\n",
    "print(f'Test accuracy: {test_acc * 100:.2f}%')\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(to_categorical(test_data['emotion'].values), axis=1)\n",
    "\n",
    "print(classification_report(y_true, y_pred_classes))\n",
    "\n",
    "print(confusion_matrix(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test accuracy: 41.99%\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.36      0.25      0.30       491\n",
    "           1       0.00      0.00      0.00        55\n",
    "           2       0.31      0.17      0.22       528\n",
    "           3       0.44      0.91      0.60       879\n",
    "           4       0.30      0.37      0.33       594\n",
    "           5       0.75      0.43      0.55       416\n",
    "           6       0.57      0.14      0.23       626\n",
    "\n",
    "    accuracy                           0.42      3589\n",
    "   macro avg       0.39      0.33      0.32      3589\n",
    "weighted avg       0.44      0.42      0.38      3589\n",
    "...\n",
    "confusion matrix\n",
    " [[ 19   0  18 802  33   2   5]\n",
    " [ 55   0  42 255 222   5  15]\n",
    " [ 28   0  67 108  25 178  10]\n",
    " [ 50   0  29 252 198   7  90]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Test. Use your trained neural network from Part B.1 and classify the Phoebe unknown image data. Report your perceived performance on the unknown labels, comparing it to the SVM in Part A.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Image: 1_01.jpg, Predicted label: 4\n",
      "Image: 4_01.jpg, Predicted label: 4\n",
      "Image: 4_20.jpg, Predicted label: 4\n",
      "Image: 8_01.jpg, Predicted label: 3\n",
      "Image: 9_41.jpg, Predicted label: 3\n",
      "Image: 26_123.jpg, Predicted label: 3\n",
      "Image: 35_42.jpg, Predicted label: 4\n",
      "Image: 41_06.jpg, Predicted label: 3\n",
      "Image: 44_01.jpg, Predicted label: 4\n",
      "Image: 46_03.jpg, Predicted label: 3\n",
      "Image: 48_01.jpg, Predicted label: 4\n",
      "Image: 52_31.jpg, Predicted label: 3\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# load the dataset to get the unknown images\n",
    "data = pd.read_csv('phoebe_AU.csv')\n",
    "unknown_data = data[data['label'] == 'unknown']\n",
    "\n",
    "model.save('cnn_b1.h5')\n",
    "\n",
    "model = load_model('cnn_b1.h5')  # load the model file\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path).convert('L')  # convert to grayscale\n",
    "    img = img.resize((48, 48))  # resize to match the input shape expected by the model\n",
    "    img_array = np.array(img)\n",
    "    img_array = img_array / 255.0\n",
    "    img_array = img_array.reshape(1, 48, 48, 1)\n",
    "    return img_array\n",
    "\n",
    "results = []\n",
    "for filename in unknown_data['file_name']:\n",
    "    image_path = f'images/unknown/{filename}' # assuming the images are in a folder called 'images'\n",
    "    img_array = preprocess_image(image_path)\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_label = np.argmax(prediction)  # assuming the labels are encoded as integers\n",
    "    results.append((filename, predicted_label))\n",
    "\n",
    "# Display the results\n",
    "for filename, label in results:\n",
    "    print(f'Image: {filename}, Predicted label: {label}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the legend from the dataset: (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral), and comparing with the images given, the model is more accurate and decisive with an emotion when compared to the SVM in Part A.2. It is so because it is giving definite and not unknown classifications for each and every image, and is mostly accurate based on my perceived performance. It seems to have misaligned with 52_31.jpg, where Phoebe looks more on the sadder side, but was labeled as happy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Fine-tune the Neural Network, and re-classify. Fine-tune your neural network on the Phoebe-face image dataset provided (Hints: use imread() in grayscale to read the images, and freeze early layer weights during fine-tuning). Then, reclassify the images in unknown. Do you think the results improved compared to Part B.2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - accuracy: 0.1054 - loss: 1.6157 - val_accuracy: 0.1111 - val_loss: 1.6463\n",
      "Epoch 2/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.1088 - loss: 1.6148 - val_accuracy: 0.1111 - val_loss: 1.6414\n",
      "Epoch 3/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.1048 - loss: 1.6330 - val_accuracy: 0.1111 - val_loss: 1.6372\n",
      "Epoch 4/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.0898 - loss: 1.6022 - val_accuracy: 0.0556 - val_loss: 1.6334\n",
      "Epoch 5/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.1472 - loss: 1.6103 - val_accuracy: 0.0556 - val_loss: 1.6305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Image: 1_01.jpg, Predicted label: angry\n",
      "Image: 4_01.jpg, Predicted label: angry\n",
      "Image: 4_20.jpg, Predicted label: angry\n",
      "Image: 8_01.jpg, Predicted label: disgust\n",
      "Image: 9_41.jpg, Predicted label: disgust\n",
      "Image: 26_123.jpg, Predicted label: disgust\n",
      "Image: 35_42.jpg, Predicted label: angry\n",
      "Image: 41_06.jpg, Predicted label: disgust\n",
      "Image: 44_01.jpg, Predicted label: disgust\n",
      "Image: 46_03.jpg, Predicted label: disgust\n",
      "Image: 48_01.jpg, Predicted label: disgust\n",
      "Image: 52_31.jpg, Predicted label: disgust\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[..., :3], [0.2989, 0.5870, 0.1140]) # convert to grayscale using the formula\n",
    "\n",
    "emotions = ['angry', 'disgust', 'surprise', 'happy', 'sad']  # emotions in the dataset\n",
    "image_data = []\n",
    "labels = []\n",
    "\n",
    "for i, emotion in enumerate(emotions):\n",
    "    emotion_dir = f'images/{emotion}/'\n",
    "    for file in os.listdir(emotion_dir):\n",
    "        # some files may not be images\n",
    "        if not file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(emotion_dir, file)\n",
    "        img = Image.open(img_path).convert('L')  # convert to grayscale\n",
    "        img = img.resize((48, 48))  # resize to 48x48 to match the input shape expected by the model\n",
    "        img_array = np.array(img) / 255.0\n",
    "        image_data.append(img_array.reshape(48, 48, 1))\n",
    "        labels.append(i)\n",
    "\n",
    "X_phoebe = np.array(image_data)\n",
    "y_phoebe = to_categorical(np.array(labels), num_classes=len(emotions))\n",
    "\n",
    "X_phoebe_train, X_phoebe_val, y_phoebe_train, y_phoebe_val = train_test_split(X_phoebe, y_phoebe, test_size=0.2)\n",
    "\n",
    "model = load_model('cnn_b1.h5') # load the model file\n",
    "\n",
    "# fine-tune the model by removing the last layer and adding a new output layer. this is needed because the number of classes is different\n",
    "base_model = model  # store the original model\n",
    "base_model.layers.pop()  # remove the last laye\n",
    "new_output = Dense(len(emotions), activation='softmax')(base_model.layers[-1].output) # add a new output layer\n",
    "new_model = Model(inputs=base_model.inputs, outputs=new_output) # create a new model with the modified output\n",
    "\n",
    "# freeze the first 5 layers\n",
    "for layer in new_model.layers[:5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# try a smaller learning rate to avoid overfitting\n",
    "new_model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "\n",
    "# fine-tune the model by training on the new dataset\n",
    "history = new_model.fit(X_phoebe_train, y_phoebe_train, epochs=5, validation_data=(X_phoebe_val, y_phoebe_val))\n",
    "\n",
    "# Save the fine-tuned model\n",
    "new_model.save('cnn_b3.h5')\n",
    "\n",
    "# load the dataset to get the unknown images\n",
    "data = pd.read_csv('phoebe_AU.csv')\n",
    "unknown_data = data[data['label'] == 'unknown']\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path).convert('L')\n",
    "    img = img.resize((48, 48))\n",
    "    img_array = np.array(img) / 255.0\n",
    "    return img_array.reshape(1, 48, 48, 1)\n",
    "\n",
    "# perform the classification\n",
    "results = []\n",
    "for filename in unknown_data['file_name']:\n",
    "    image_path = f'images/unknown/{filename}'\n",
    "    img_array = preprocess_image(image_path)\n",
    "    prediction = new_model.predict(img_array)\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    results.append((filename, emotions[predicted_label]))  # convert the label back to the original emotion\n",
    "\n",
    "# show the results\n",
    "for filename, label in results:\n",
    "    print(f'Image: {filename}, Predicted label: {label}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model seems to have almost the same performance when compared to Part B.2 as there are only 2 main emotions presented in the model predictions; angry and disgust. This may be part in due to the fact that the original neural network had 7 dense layers (due to the varied different emotions from the fer2013 dataset), but this newly trained neural network has been condensed down to 5 dense layers to account for the phoebe and Action Units dataset, which may be outputting a more generalized performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part C - Comparison between Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Compare. Compare the results from the 4 models (SVM-Fer2013, SVM-OpenFace, NN-Fer2013, NN-FineTuned) on the Phoebe unknown dataset. Specifically compare the approach with hand-crafted features (SVM-OpenFace) versus neural network extracted features (NN-FineTuned). Choose the one that you think worked best with this dataset. Justify your answer based on the results from Part A and Part B and discuss limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Part C, it becomes evident that the neural network finetuned model outperforms on the Phoebe dataset due to the variation in dense output layers of the network itself. The SVM opened-faced model falls short in capturing the nuanced emotional expressions compared to the neutral network because of the dense and KFold parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
